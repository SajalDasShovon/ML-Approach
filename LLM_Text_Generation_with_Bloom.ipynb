{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN7mB+wX2KXJDaRJS4szsv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SajalDasShovon/ML-Approach/blob/main/LLM_Text_Generation_with_Bloom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2vXCTNIZHwZ",
        "outputId": "58ffdf20-3dab-4816-c1c3-f6f5be0a39df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.35.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, set_seed"
      ],
      "metadata": {
        "id": "BKhS1LK7hkck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b7\")\n"
      ],
      "metadata": {
        "id": "O1osrQTMhkZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModel.from_pretrained(\"bigscience/bloom-1b7\")\n",
        "\n",
        "#model_lm = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b7\")"
      ],
      "metadata": {
        "id": "7kDxuqWhhkXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ZrTLH3V-hkGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b271faf-0875-4e41-d11f-d4f85daca4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BloomModel(\n",
              "  (word_embeddings): Embedding(250880, 2048)\n",
              "  (word_embeddings_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "  (h): ModuleList(\n",
              "    (0-23): 24 x BloomBlock(\n",
              "      (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (self_attention): BloomAttention(\n",
              "        (query_key_value): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): BloomMLP(\n",
              "        (dense_h_to_4h): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (gelu_impl): BloomGelu()\n",
              "        (dense_4h_to_h): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.__class__"
      ],
      "metadata": {
        "id": "nWRn1j9phkCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb88adc-7bf3-420f-9869-34d843623c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bloom.modeling_bloom.BloomModel"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.__class__.__name__"
      ],
      "metadata": {
        "id": "8zjejXz1hj-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "97cacf72-8205-4185-d62e-c49bca49d530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BloomModel'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(11111)"
      ],
      "metadata": {
        "id": "sthcMYpJhj6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_prompt='What is life in the 20th Century?'"
      ],
      "metadata": {
        "id": "leTRuEHjjxLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "input_tokens = tokenizer(text_prompt, return_tensors=\"pt\").to(0)"
      ],
      "metadata": {
        "id": "92hQwmIpjxJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens"
      ],
      "metadata": {
        "id": "StzLJ3r1jxHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817e6a7e-9cba-4c41-da0e-d132030dbcca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 10560,    632,  10440,    361,    368, 106234, 103126,     34]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lm = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b7\")\n",
        "#result_sample = model.generate(**input_tokens, max_length=200, top_k=0, temperature=0.5)\n"
      ],
      "metadata": {
        "id": "KKS1N3JTjxFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_sample = model_lm.generate(**input_tokens, max_length=200, top_k=0, temperature=0.5)"
      ],
      "metadata": {
        "id": "LJ1lf_JLjxDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_sample"
      ],
      "metadata": {
        "id": "XKP3rplKjxBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdb3853-5c2a-48f5-b11e-765c0adcd5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 10560,    632,  10440,    361,    368, 106234, 103126,     34,   3162,\n",
              "            632,    267,   3509,    461,  10087,   7458,     15,    530,    368,\n",
              "           8876,    632,  35179,     17,   1387,   8876,    632,  35179,   5908,\n",
              "            461,    368,  28770,    861,    632,  35179,    368,   4676,   1701,\n",
              "          20152,     17,   1387,   8876,    632,  35179,   5908,    461,    368,\n",
              "           4676,   1701,   6482,     17,   1387,   8876,    632,  35179,   5908,\n",
              "            461,    368,   4676,   1701,  85392,     17,   1387,   8876,    632,\n",
              "          35179,   5908,    461,    368,   4676,   1701,   2909,     17,   1387,\n",
              "           8876,    632,  35179,   5908,    461,    368,   4676,   1701,  20152,\n",
              "             17,   1387,   8876,    632,  35179,   5908,    461,    368,   4676,\n",
              "           1701,   6482,     17,   1387,   8876,    632,  35179,   5908,    461,\n",
              "            368,   4676,   1701,  85392,     17,   1387,   8876,    632,  35179,\n",
              "           5908,    461,    368,   4676,   1701,   2909,     17,   1387,   8876,\n",
              "            632,  35179,   5908,    461,    368,   4676,   1701,  20152,     17,\n",
              "           1387,   8876,    632,  35179,   5908,    461,    368,   4676,   1701,\n",
              "           6482,     17,   1387,   8876,    632,  35179,   5908,    461,    368,\n",
              "           4676,   1701,  85392,     17,   1387,   8876,    632,  35179,   5908,\n",
              "            461,    368,   4676,   1701,   2909,     17,   1387,   8876,    632,\n",
              "          35179,   5908,    461,    368,   4676,   1701,  20152,     17,   1387,\n",
              "           8876,    632,  35179,   5908,    461,    368,   4676,   1701,   6482,\n",
              "             17,   1387,   8876,    632,  35179,   5908,    461,    368,   4676,\n",
              "           1701,  85392,     17,   1387,   8876,    632,  35179,   5908,    461,\n",
              "            368,   4676]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_sample[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss6RPAD92_jX",
        "outputId": "bbd9af11-6b85-4a7e-d997-7c1bd84664b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 10560,    632,  10440,    361,    368, 106234, 103126,     34,   3162,\n",
              "           632,    267,   3509,    461,  10087,   7458,     15,    530,    368,\n",
              "          8876,    632,  35179,     17,   1387,   8876,    632,  35179,   5908,\n",
              "           461,    368,  28770,    861,    632,  35179,    368,   4676,   1701,\n",
              "         20152,     17,   1387,   8876,    632,  35179,   5908,    461,    368,\n",
              "          4676,   1701,   6482,     17,   1387,   8876,    632,  35179,   5908,\n",
              "           461,    368,   4676,   1701,  85392,     17,   1387,   8876,    632,\n",
              "         35179,   5908,    461,    368,   4676,   1701,   2909,     17,   1387,\n",
              "          8876,    632,  35179,   5908,    461,    368,   4676,   1701,  20152,\n",
              "            17,   1387,   8876,    632,  35179,   5908,    461,    368,   4676,\n",
              "          1701,   6482,     17,   1387,   8876,    632,  35179,   5908,    461,\n",
              "           368,   4676,   1701,  85392,     17,   1387,   8876,    632,  35179,\n",
              "          5908,    461,    368,   4676,   1701,   2909,     17,   1387,   8876,\n",
              "           632,  35179,   5908,    461,    368,   4676,   1701,  20152,     17,\n",
              "          1387,   8876,    632,  35179,   5908,    461,    368,   4676,   1701,\n",
              "          6482,     17,   1387,   8876,    632,  35179,   5908,    461,    368,\n",
              "          4676,   1701,  85392,     17,   1387,   8876,    632,  35179,   5908,\n",
              "           461,    368,   4676,   1701,   2909,     17,   1387,   8876,    632,\n",
              "         35179,   5908,    461,    368,   4676,   1701,  20152,     17,   1387,\n",
              "          8876,    632,  35179,   5908,    461,    368,   4676,   1701,   6482,\n",
              "            17,   1387,   8876,    632,  35179,   5908,    461,    368,   4676,\n",
              "          1701,  85392,     17,   1387,   8876,    632,  35179,   5908,    461,\n",
              "           368,   4676])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_sample[0]\n",
        "print(tokenizer.decode(result_sample[0], truncate_before_pattern=[r\"\\n\\n^#\", \"^'''\", \"\\n\\n\\n\"]))"
      ],
      "metadata": {
        "id": "UEGqhRvijw-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9dff498-d43f-4b9c-8348-929f55c23293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is life in the 20th Century? It is a time of great change, and the world is changing. The world is changing because of the technology that is changing the way we live. The world is changing because of the way we think. The world is changing because of the way we communicate. The world is changing because of the way we work. The world is changing because of the way we live. The world is changing because of the way we think. The world is changing because of the way we communicate. The world is changing because of the way we work. The world is changing because of the way we live. The world is changing because of the way we think. The world is changing because of the way we communicate. The world is changing because of the way we work. The world is changing because of the way we live. The world is changing because of the way we think. The world is changing because of the way we communicate. The world is changing because of the way\n"
          ]
        }
      ]
    }
  ]
}